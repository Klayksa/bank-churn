{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d89252e",
   "metadata": {},
   "source": [
    "# Прогнозирование оттока клиентов банка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7769c",
   "metadata": {},
   "source": [
    "### Постановка бизнес-задачи, описание предметной области.  \n",
    "\n",
    "#### Предметная область\n",
    "Рассматривается задача прогнозирования оттока клиентов банка. Отток (churn) - прекращение использования клиентом банковских услуг. Удержание клиентов - приоритет для бизнеса из-за высокой стоимости их привлечения.  \n",
    "\n",
    "---\n",
    "#### Контекст бизнеса\n",
    "\n",
    "**Банки стремятся**:\n",
    "- Выявлять клиентов с высоким риском ухода\n",
    "- Повышать уровень удержания\n",
    "- Персонализировать предложения\n",
    "\n",
    "**Ключевые аспекты:**\n",
    "- Своевременное выявление оттока\n",
    "- Оптимизация маркетинговых и удерживающих кампаний\n",
    "- Увеличение прибыли за счёт лояльных клиентов\n",
    "\n",
    "---\n",
    "#### Бизнес-задача\n",
    "Разработать модель машинного обучения для предсказания ухода клиента на основе его характеристик.\n",
    "\n",
    "**Цель:**\n",
    "- Снизить отток клиентов\n",
    "- Поддержки стабильной прибыли банков\n",
    "- Улучшения стратегий взаимодействия с клиентами\n",
    "\n",
    "---\n",
    "#### Описание набора данных\n",
    "**Источник:** Kaggle - [Bank Customer Churn Prediction](https://www.kaggle.com/datasets/shubhammeshram579/bank-customer-churn-prediction)  \n",
    "**Объём:** ~10 000 клиентов  \n",
    "**Целевая переменная:** `Exited` (1 — клиент ушёл, 0 — остался)\n",
    "\n",
    "**Основные признаки**\n",
    "\n",
    "| Признак                | Тип            | Описание                                                  |\n",
    "|------------------------|----------------|-----------------------------------------------------------|\n",
    "| `CustomerId`           | Integer        | Уникальный идентификатор клиента                          |\n",
    "| `Surname`              | String         | Фамилия клиента                                           |\n",
    "| `CreditScore`          | Integer        | Кредитный рейтинг клиента                                 |\n",
    "| `Geography`            | String         | Страна проживания                                         |\n",
    "| `Gender`               | String         | Пол клиента                                               |\n",
    "| `Age`                  | Integer        | Возраст клиента                                           |\n",
    "| `Tenure`               | Integer        | Лет сотрудничества                                        |\n",
    "| `Balance`              | Float          | Остаток на счёте                                          |\n",
    "| `NumOfProducts`        | Integer        | Кол-во продуктов банка                                    |\n",
    "| `HasCrCard`            | Integer        | Наличие кредитной карты                                   |\n",
    "| `IsActiveMember`       | Float          | Активность клиента                                        |\n",
    "| `EstimatedSalary`      | Float          | Предполагаемый доход                                      |\n",
    "| `Exited`               | Integer        | Ушел ли клиент или нет (целевая переменная)               |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a2e1d",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef70079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c150c00",
   "metadata": {},
   "source": [
    "#### Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1437bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка дата сета\n",
    "data_set = pd.read_csv(\"../data/churn.csv\")\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca8f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первые 10 строк\n",
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# последние 10 строк\n",
    "data_set.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f69b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# случайные 10 строк\n",
    "data_set.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f59ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# название колонок в датасете\n",
    "data_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# размер датасета\n",
    "data_set.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Общие сведения о датасете \n",
    "data_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d574e67",
   "metadata": {},
   "source": [
    "#### Проблемы при беглом анализе\n",
    "При беглом осмотре можно сразу заметить несколько проблем в данном датасете:  \n",
    "1. Колонка RowNumber - по сути является счетчиком строк, что не нужно, т.к порядок строки в данных не влияет на результат\n",
    "2. Колонка CustomerId - уникальный идентификатор клиента, по сути не влияет на результат\n",
    "3. В колонке Age значения представлены в виде чисел с плавающей точкой (float), хотя возраст исчисляется целочисленно\n",
    "4. Колонки HasCrCard и IsActiveMember, возможно, содержат числа с плавающей точкой. В описании данных четко указано, что значениями могут быть только 1 (Да) и 0 (Нет)\n",
    "5. Колонка Gender, возможно, имеет только 2 значения - Male и Female, можно ввести ассоциацию: 1 (Male) и 2 (Female)\n",
    "6. Колонка Geography имеет только 3 значения - можно ввести ассоциацию: 1 (France), 2 (Spain), 3 (Germany)\n",
    "7. Были замечены пустые значения\n",
    "8. Названия колонок не соответствуют \"змеиному регистру\"\n",
    "9. У некоторых имен имеются спец символы\n",
    "10. У некоторых фамилий обнаружены спец. символы (например H? в строке с индексом 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f95da3",
   "metadata": {},
   "source": [
    "#### Детальный анализ датасета и каждого столбца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# типы данных каждого столбца\n",
    "data_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f763ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# точное измерение памяти\n",
    "data_set.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск пустых значений по столбцам\n",
    "data_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# детальный анализ каждого столбца\n",
    "\n",
    "for column in data_set.columns:\n",
    "    print(f\"Колонка {column}\")\n",
    "    print(f\"Тип данных: {data_set[column].dtype}\")\n",
    "    print(f\"Количество пустых значений: {data_set[column].isnull().sum()}\")\n",
    "    print(f\"Количество уникальных значений: {data_set[column].nunique()}\")\n",
    "    print(f\"Уникальные значения: {data_set[column].unique()}\")\n",
    "    print(f\"{data_set[column].describe()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fee330",
   "metadata": {},
   "source": [
    "При детальном анализе выявлены пустые значения, а также обнаружены столбцы, где можно привести данные в нормальную форму, например в колонке Age нужно привести к типу int.  \n",
    "Также было определено, что колонки Geography, Gender являются категориальными - это значит, что тип данных object можно привести к int с помощью ассоциаций."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bcd3bc",
   "metadata": {},
   "source": [
    "#### Исправление датасета \n",
    "Сначала обработаем регистры в столбцах и в значениях столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65923b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исправление регистров столбцов и приведение к \"змеиному регистру\"\n",
    "data_set.columns = (\n",
    "    data_set.columns\n",
    "    .str.replace(r'(?<=[a-z])([A-Z])', r'_\\1', regex=True)\n",
    "    .str.lower()\n",
    ")\n",
    "data_set.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3771ccf",
   "metadata": {},
   "source": [
    "Далее удалим столбцы row_number и customer_id, но столбец surname оставим для дальнейшего анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.drop([\"row_number\", \"customer_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822ddd3",
   "metadata": {},
   "source": [
    "При анализе столбца фамилий было обнаружено, что из 10 000 фамилий только уникальных фамилий только 2932, а значит для оптимизации памяти и сохранения конфиденциальности клиентов можно создать ассоциативный словарь фамилий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ca82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведение имен к нижнему регистру и удаление спецсимволы\n",
    "data_set[\"surname\"] = data_set[\"surname\"].str.lower().str.replace(r'[^\\w_]', '', regex=True)\n",
    "\n",
    "# в pandas есть функция factorize, которая создает список уникальных значений, а в колонке заменяет фамилии на число\n",
    "data_set[\"surname\"], surnames = pd.factorize(data_set[\"surname\"])\n",
    "\n",
    "# т.к factorize возвращает только список уникальных фамилий, необходимо сделать 2 (на всякий случай) словаря форматов: число:фамилия и фамилия:число\n",
    "SURNAMES_VAL = dict(enumerate(surnames))\n",
    "SURNAMES_ID = {val: key for key, val in SURNAMES_VAL.items()}\n",
    "\n",
    "# для самостоятельной проверки корректности преобразования вывод списка имен\n",
    "SURNAMES_VAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b912a2b",
   "metadata": {},
   "source": [
    "Для столбцов gender и geography регистр менять не будем, а заменим строковые (object) значения на числовые, где 1 это будет male, а 2 - female для gender и 1 - France, 2 - Spain, 3 - Germany для geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a01de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание ассоциаций\n",
    "GENDER_VAL = {\n",
    "    1: \"male\",\n",
    "    2: \"female\"\n",
    "}\n",
    "\n",
    "GEOGRAPHY_VAL = {\n",
    "    1: \"france\",\n",
    "    2: \"spain\",\n",
    "    3: \"germany\"\n",
    "}\n",
    "# обратный словарь на всякий случай\n",
    "GENDER_ID = {val: key for key, val in GENDER_VAL.items()}\n",
    "GEOGRAPHY_ID = {val: key for key, val in GEOGRAPHY_VAL.items()}\n",
    "\n",
    "# функции для отображения значений (возможно не понадобится вообще)\n",
    "def get_gender_value(num: int) -> str:\n",
    "    return GENDER_VAL[num]\n",
    "\n",
    "def get_gender_id(val: str) -> int:\n",
    "    return GENDER_ID[val]\n",
    "\n",
    "def get_geography_value(num: int) -> str:\n",
    "    return GEOGRAPHY_VAL[num]\n",
    "\n",
    "def get_geography_id(val: str) -> int:\n",
    "    return GEOGRAPHY_ID[val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# замена значений на ассоциации\n",
    "data_set[\"gender\"] = data_set[\"gender\"].map({\"Male\": 1, \"Female\": 2})\n",
    "data_set[\"geography\"] = data_set[\"geography\"].map({\"France\": 1, \"Spain\": 2, \"Germany\": 3})\n",
    "data_set.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3901d",
   "metadata": {},
   "source": [
    "Обратим внимание, что в колонке geography неверно установился тип данных  \n",
    "Возможно это связано с наличием пропусков в колонке. Далее будет рассмотрена обработка пропусков и преобразование типов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb19b4",
   "metadata": {},
   "source": [
    "#### Обработка пропусков\n",
    "В датасете было обнаружено 4 пропуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_missing = data_set[data_set.isna().any(axis=1)]\n",
    "rows_with_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08683a32",
   "metadata": {},
   "source": [
    "Для каждой замены необходимо выбрать те методы, которые сохранят статические свойства данных:\n",
    "1. Для категориального значения в столбце geography воспользуемся модой (превалирующие значения) для сохранения распределения\n",
    "2. Для значения в столбце age воспользуемся медианой, которая устойчива к выбросам (среднее не учитывает возможные выбросы)\n",
    "3. Для значения в столбце has_cr_card воспользуемся логикой)) Если данные о кредитной карте отсутствуют в системе, то логично предположить, что у клиента нет кредитной карты\n",
    "4. Для значения в столбце is_active_member для минимизации искажения воспользуемся медианой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc76181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geography \n",
    "data_set.loc[6, 'geography'] = data_set['geography'].mode()[0]\n",
    "\n",
    "# age\n",
    "data_set.loc[9, 'age'] = data_set['age'].median()\n",
    "\n",
    "# has_cr_card\n",
    "data_set.loc[4, 'has_cr_card'] = 0\n",
    "\n",
    "# is_active_member\n",
    "data_set.loc[8, 'is_active_member'] = data_set['is_active_member'].median()\n",
    "\n",
    "# перепроверка пропусков\n",
    "data_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922ade1",
   "metadata": {},
   "source": [
    "#### Приведение значений столбцов к необходимым типам данных\n",
    "В ходе анализа датасета установлено, что необходимо изменить следующие типы данных:\n",
    "1. credit_score с int64 на int32 (оптимизация памяти)\n",
    "2. geography с float на int8 (изначально неверный тип данных)\n",
    "3. gender с int64 на int8 (оптимизация памяти)\n",
    "4. age с float на int8 (изначально неверный тип данных)\n",
    "5. tenure c int64 на int8 (оптимизация памяти)\n",
    "6. num_of_products с int32 на int16 (оптимизация памяти)\n",
    "7. has_cr_card с float на bool (неверный тип данных)\n",
    "8. is_active_member c float на bool (неверный тип данных)\n",
    "9.  exited с int на bool (неверный тип данных)\n",
    "    \n",
    "В основном изменения типов данных нужны для оптимизации памяти, но присутствуют и неверные типы данных\n",
    "\n",
    "Также нужно учесть особенности работы pandas с работой чисел с плавающей точкой (float):  \n",
    "float64 является стандартным представлением чисел с плавающей точкой в pandas и в начальных настройках отображения данных автоматически показывает только 2 знака после точки, хотя float64 имеет точность ~16 знаков после запятой. Изменение данного типа данных на float32 может привести к большему накоплению ошибок, чем float64.  \n",
    "Для денежных форматов необходимо использовать тип данных Decimal, но т.к датасет носит учебный характер - можно оставить float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.astype({\n",
    "    'credit_score': 'int32',\n",
    "    'geography': 'int8',\n",
    "    'gender': 'int8',\n",
    "    'age': 'int8',\n",
    "    'tenure': 'int8',\n",
    "    'num_of_products': 'int16',\n",
    "    'has_cr_card': 'bool',\n",
    "    'is_active_member': 'bool',\n",
    "    'exited': 'bool'\n",
    "})\n",
    "\n",
    "# проверка отработало ли преобразование типов корректно или нет\n",
    "data_set.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118c554",
   "metadata": {},
   "source": [
    "#### Поиск дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск дубликатов\n",
    "data_set.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# т.к нашлись дубликаты, выведем их\n",
    "duplicates = data_set[data_set.duplicated(keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f7b95",
   "metadata": {},
   "source": [
    "На печати видно, что дубликаты полностью идентичны (9998 с 9999 и 10000 с 10001).\n",
    "Это может быть связано с разными причинами, например, ошибка при выгрузке датасета (на api или бд могли произойти сбои, которые вызвали повторную запись - это маловероятно, но не равно 0). Также стоит учесть, что это датасет для обучающихся и дублирование данных могло произойти нарочно.  \n",
    "Также стоит учесть, что могло произойти некорректное объединение нескольких датасетов в один.  \n",
    "Для устранения дублирования удалим дубликаты с сохранением одного экземпляра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.drop_duplicates()\n",
    "data_set.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae19156",
   "metadata": {},
   "source": [
    "#### Проверка датасета после предобработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06139e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa930fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2dea6",
   "metadata": {},
   "source": [
    "#### Вывод по первому этапу\n",
    "\n",
    "В ходе предварительного анализа и обработки набора данных были выполнены следующие шаги и устранены выявленные проблемы:\n",
    "\n",
    "1. Были просмотрены первые и последние строки, случайная выборка, структура датасета, типы данных и использование памяти.  \n",
    "   Это позволило сформировать общее представление о содержимом датасета и выявить потенциальные проблемы: наличие ненужных столбцов, неунифицированные имена, категориальные признаки в строковом формате, пропуски в данных, дублирование данных и несоответствие типов данных.\n",
    "\n",
    "2. При анализе датасета были выявлены:\n",
    "   - Наличие неинформативных столбцов (`row_number`, `customer_id`), которые были удалены из датасета;\n",
    "   - Несоблюдение стиля наименования столбцов (`\"змеиного регистра\"`). В процессе обработки все строковые значения (включая название столбцов) были приведены к этому стилю;\n",
    "   - Наличие строкового формата у категориальных признаков (`gender`, `geography`). Для решения данной проблемы были созданы отдельные словари, а в датасете использованы цифровые ключи;\n",
    "   - Наличие пустых значений и дубликатов, которые в процессе были устранены;\n",
    "   - Несоответствие типов данных. После предобработки все данные были приведены к необходимым типам\n",
    "\n",
    "3. Столбец `surname` был очищен от специальных символов и приведён к нижнему регистру, после чего был закодирован с помощью pd.factorize, что позволило превратить строковый столбец в числовой идентификатор.\n",
    "   \n",
    "Таким образом данные были подготовлены к дальнейшему анализу.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
